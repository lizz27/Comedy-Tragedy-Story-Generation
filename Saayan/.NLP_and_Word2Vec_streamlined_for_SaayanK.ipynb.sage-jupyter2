{"backend_state":"running","connection_file":"/projects/6a848d56-5da1-43fb-bfc9-9172977ceeb4/.local/share/jupyter/runtime/kernel-8d8d0f6e-1d31-4d61-a665-41ccf7b9b8f8.json","kernel":"nlp_env","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"interpreter":{"hash":"335ee12212264728feb72f243af72c5a8ea26c832f07e1f651ce9e17c7ceae23"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{},"version_major":2,"version_minor":0}}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1656600311020,"exec_count":31,"id":"b86059","input":"nltk.download('averaged_perceptron_tagger')","kernel":"nlp_env","output":{"0":{"name":"stderr","text":"[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /projects/6a848d56-5da1-43fb-\n[nltk_data]     bfc9-9172977ceeb4/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"},"1":{"data":{"text/plain":"True"},"exec_count":31}},"pos":24,"start":1656600311000,"state":"done","type":"cell"}
{"cell_type":"code","end":1656600313465,"exec_count":32,"id":"7fa9da","input":"# POS Tagging example\n# CC - coordinating conjunction\n# NN - noun, singular (cat, tree)\nall_words = nltk.word_tokenize(text)  ###If we want to look at part of speech taking before we stem/lem\n\ntagged_words = nltk.pos_tag(all_words)\n##Creates a list of lists where each element of the list is [word,partofspeech abbreviation]\n\n# Tagged word paragraph\nword_tags = []\nfor tw in tagged_words:\n    word_tags.append(tw[0]+\"_\"+tw[1])\n\ntagged_paragraph = ' '.join(word_tags)\n\n'''\nYour code here: print the first 1000 characters of tagged_paragraph.\n'''\ntagged_paragraph[:1000]","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"\"portuguese_JJ professional_JJ footballer_NN eponyms_NN films_NNS cristiano_VBP ronaldo_JJ dos_NN santos_NN aveiro_NN goih_NN comm_NN (_( portuguese_JJ pronunciation_NN :_: [_JJ kɾiʃˈtjɐnu_NN ʁɔˈnaɫdu_NNP ]_NNP ;_: born_VBN february_NN )_) is_VBZ a_DT portuguese_JJ professional_JJ footballer_NN who_WP plays_VBZ as_IN a_DT forward_NN for_IN premier_JJR league_NN club_NN manchester_NN united_JJ and_CC captains_VBZ the_DT portugal_JJ national_JJ team_NN ._. often_RB considered_VBD the_DT best_JJS player_NN in_IN the_DT world_NN and_CC widely_RB regarded_VBD as_IN one_CD of_IN the_DT greatest_JJS players_NNS of_IN all_DT time_NN ,_, ronaldo_NN has_VBZ won_VBN five_CD ballon_NN d'or_NN awards_NNS [_VBP note_NN ]_NN and_CC four_CD european_JJ golden_JJ shoes_NNS ,_, the_DT most_RBS by_IN a_DT european_JJ player_NN ._. he_PRP has_VBZ won_VBN trophies_NNS in_IN his_PRP$ career_NN ,_, including_VBG seven_CD league_JJ titles_NNS ,_, five_CD uefa_JJ champions_NNS leagues_NNS ,_, one_CD uefa_JJ eur\""},"exec_count":32}},"pos":25,"start":1656600312727,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601089832,"exec_count":73,"id":"bfcc74","input":"# Install NLTK - pip install nltk\nimport nltk\nnltk.download('wordnet')\nnltk.download('punkt')","kernel":"nlp_env","output":{"0":{"name":"stderr","text":"[nltk_data] Downloading package wordnet to\n[nltk_data]     /projects/6a848d56-5da1-43fb-\n[nltk_data]     bfc9-9172977ceeb4/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /projects/6a848d56-5da1-43fb-\n[nltk_data]     bfc9-9172977ceeb4/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"},"1":{"data":{"text/plain":"True"},"exec_count":73}},"pos":2,"start":1656601089821,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601092154,"exec_count":75,"id":"38b621","input":"import urllib\nimport bs4 as bs\nimport re","kernel":"nlp_env","pos":4,"start":1656601092152,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601094002,"exec_count":76,"id":"417757","input":"# We will read the contents of the Wikipedia article \"Global_warming\" as an example, please feel free to use your own! You can use the url below:\nurl = 'https://en.wikipedia.org/wiki/Cristiano_Ronaldo' # you can change this to use other sites as well.\n\n# We can open the page using \"urllib.request.urlopen\" then read it using \".read()\"\nsource = urllib.request.urlopen(url).read()\n\n# Beautiful Soup is a Python library for pulling data out of HTML and XML files.\n# you may need to install a parser library --> \"!pip3 install lxml\"\n# Parsing the data/creating BeautifulSoup object\n\nsoup = bs.BeautifulSoup(source,\"html.parser\") \n\n# Fetching the data\ntext = \"\"\nfor paragraph in soup.find_all('p'): #The <p> tag defines a paragraph in the webpages\n    text += paragraph.text\n\n# Preprocessing the data\n\ntext = re.sub(r'\\[[0-9]*\\]',' ',text) # [0-9]* --> Matches zero or more repetitions of any digit from 0 to 9\ntext = text.lower() #everything to lowercase\ntext = re.sub(r'\\W^.?!',' ',text) # \\W --> Matches any character which is not a word character except (.?!)\ntext = re.sub(r'\\d',' ',text) # \\d --> Matches any decimal digit\ntext = re.sub(r'\\s+',' ',text) # \\s --> Matches any characters that are considered whitespace (Ex: [\\t\\n\\r\\f\\v].)","kernel":"nlp_env","pos":5,"start":1656601092757,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601095353,"exec_count":77,"id":"34e423","input":"text[:100]","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"' portuguese professional footballer eponyms films cristiano ronaldo dos santos aveiro goih comm (por'"},"exec_count":77}},"pos":6,"start":1656601095342,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601100537,"exec_count":78,"id":"3b7f8c","input":"'''\nYour code here: Tokenize the words from the data and set it to a variable called words.\nHint: how to this might be on the very home page of NLTK!\n'''\nwords = nltk.word_tokenize(text)","kernel":"nlp_env","pos":8,"start":1656601100464,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601101323,"exec_count":79,"id":"d4dc35","input":"print(words[:10])","kernel":"nlp_env","output":{"0":{"name":"stdout","text":"['portuguese', 'professional', 'footballer', 'eponyms', 'films', 'cristiano', 'ronaldo', 'dos', 'santos', 'aveiro']\n"}},"pos":9,"start":1656601101319,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601101983,"exec_count":80,"id":"84e28d","input":"'''\nYour code here: Tokenize the sentences from the data  and set it to a variable called sentences.\nHint: try googling how to tokenize sentences in NLTK!\n'''\nsentences = nltk.sent_tokenize(text)","kernel":"nlp_env","pos":10,"start":1656601101976,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601102877,"exec_count":81,"id":"887ef6","input":"print(sentences[:10])","kernel":"nlp_env","output":{"0":{"name":"stdout","text":"[' portuguese professional footballer eponyms films cristiano ronaldo dos santos aveiro goih comm (portuguese pronunciation: [kɾiʃˈtjɐnu ʁɔˈnaɫdu]; born february ) is a portuguese professional footballer who plays as a forward for premier league club manchester united and captains the portugal national team.', \"often considered the best player in the world and widely regarded as one of the greatest players of all time, ronaldo has won five ballon d'or awards[note ] and four european golden shoes, the most by a european player.\", 'he has won trophies in his career, including seven league titles, five uefa champions leagues, one uefa european championship, and one uefa nations league.', 'ronaldo holds the records for most appearances ( ), most goals ( ), and assists ( ) in the champions league, most goals in the european championship ( ), most international goals by a male player ( ), and most international appearances by a european male ( ).', 'he is one of the few players to have made over , professional career appearances, and has scored over official senior career goals for club and country.', 'ronaldo began his senior career with sporting cp, before signing with manchester united in , aged , winning the fa cup in his first season.', \"he would also go onto win three consecutive premier league titles, the champions league and the fifa club world cup; at age , he won his first ballon d'or.\", \"ronaldo was the subject of the then-most expensive association football transfer when he signed for real madrid in in a transfer worth € million (£ million), where he won trophies, including two la liga titles, two copa del rey, and four champions leagues, and became the club's all-time top goalscorer.\", \"he won back-to-back ballons d'or in and , and again in and , and was runner-up three times behind lionel messi, his perceived career rival.\", 'in , he signed for juventus in a transfer worth an initial € million (£ million), the most expensive transfer for an italian club and the most expensive for a player over years old.']\n"}},"pos":11,"start":1656601102850,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601105658,"exec_count":82,"id":"a3dc07","input":"nltk.download('stopwords')\nfrom nltk.corpus import stopwords","kernel":"nlp_env","output":{"0":{"name":"stderr","text":"[nltk_data] Downloading package stopwords to\n[nltk_data]     /projects/6a848d56-5da1-43fb-\n[nltk_data]     bfc9-9172977ceeb4/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"}},"pos":13,"start":1656601105655,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601182329,"exec_count":94,"id":"47400d","input":"'''\ndefine a function called \"remove_stopwords\" that takes in a list of the sentences of the text and returns one that doesn't have any stopwords.\n'''\ndef remove_stopwords(sentences):\n    \n    for i in range(len(sentences)):\n        words = []\n        word_list = nltk.word_tokenize(sentences[i])\n        \n        for word in word_list:\n            if word not in stopwords.words('english'):\n                words.append(word)\n        sentences[i]  = ' '.join(words)\n    \n    return sentences\n\n###Then actually apply your function###\nsentences = remove_stopwords(sentences)\nprint(sentences[:10]) #Check if it worked correctly. Are all stopwords removed?\n","kernel":"nlp_env","output":{"0":{"name":"stdout","text":"['portuguese professional footballer eponyms films cristiano ronaldo dos santos aveiro goih comm portuguese pronunciation : [ kɾiʃˈtjɐnu ʁɔˈnaɫdu ] ; born february portuguese professional footballer plays forward premier league club manchester united captains portugal national team', \"often considered best player world widely regarded one greatest players time ronaldo five ballon d'or awards [ note ] four european golden shoes european player\", 'trophies career including seven league titles five uefa champions leagues one uefa european championship one uefa nations league', 'ronaldo holds records appearances goals assists champions league goals european championship international goals male player international appearances european male', 'one players made professional career appearances scored official senior career goals club country', 'ronaldo began senior career sporting cp signing manchester united aged winning fa cup first season', \"would also go onto win three consecutive premier league titles champions league fifa club world cup ; age first ballon d'or\", \"ronaldo subject then-most expensive association football transfer signed real madrid transfer worth € million £ million trophies including two la liga titles two copa del rey four champions leagues became club 's all-time top goalscorer\", \"back-to-back ballons d'or runner-up three times behind lionel messi perceived career rival\", 'signed juventus transfer worth initial € million £ million expensive transfer italian club expensive player years old']\n"}},"pos":14,"scrolled":true,"start":1656601181501,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601189421,"exec_count":96,"id":"1acdc9","input":"from nltk.stem import WordNetLemmatizer\n    \n## Step 1: Import the lemmatizer\nlemmatizer = WordNetLemmatizer()\n\n'''\nYour code here: Define a function called \"lem_sentences\" that: loops through the sentences, split the sentences up by words and applies \"lemmatizer.lemmatize\" to each word and then join everything back into a sentence\n'''\n##Similar to stopwords: For loop through the sentences, split by words and apply \"lemmatizer.lemmatize\" to each word and join back into a sentence\ndef lem_sentences(sentences):\n    for i in range(len(sentences)):\n\n        words = []\n\n        word_list = nltk.word_tokenize(sentences[i])\n\n        for word in word_list:\n            words.append(lemmatizer.lemmatize(word))\n\n        sentences[i] = ' '.join(words)\n    \n    return sentences\nsentences = lem_sentences(sentences)\nprint(sentences[:10]) ","kernel":"nlp_env","output":{"0":{"name":"stdout","text":"['portuguese professional footballer eponym film cristiano ronaldo do santos aveiro goih comm portuguese pronunciation : [ kɾiʃˈtjɐnu ʁɔˈnaɫdu ] ; born february portuguese professional footballer play forward premier league club manchester united captain portugal national team', \"often considered best player world widely regarded one greatest player time ronaldo five ballon d'or award [ note ] four european golden shoe european player\", 'trophy career including seven league title five uefa champion league one uefa european championship one uefa nation league', 'ronaldo hold record appearance goal assist champion league goal european championship international goal male player international appearance european male', 'one player made professional career appearance scored official senior career goal club country', 'ronaldo began senior career sporting cp signing manchester united aged winning fa cup first season', \"would also go onto win three consecutive premier league title champion league fifa club world cup ; age first ballon d'or\", \"ronaldo subject then-most expensive association football transfer signed real madrid transfer worth € million £ million trophy including two la liga title two copa del rey four champion league became club 's all-time top goalscorer\", \"back-to-back ballons d'or runner-up three time behind lionel messi perceived career rival\", 'signed juventus transfer worth initial € million £ million expensive transfer italian club expensive player year old']\n"}},"pos":21,"start":1656601189301,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601234177,"exec_count":108,"id":"2de21c","input":"# code to print a wordcloud for your sentences\nwordcloud = WordCloud(\n                        background_color='white',\n                        max_words=100,\n                        max_font_size=50, \n                        random_state=42\n                        ).generate(str(sentences))\nfig = plt.figure(1)\nplt.figure(figsize=(10,10))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"<Figure size 432x288 with 0 Axes>"}},"1":{"data":{"image/png":"48631c5cd1853db409d059b9d4ef59b8d8e10911","text/plain":"<Figure size 720x720 with 1 Axes>"},"metadata":{"needs_background":"light"}}},"pos":40,"start":1656601233841,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601309770,"exec_count":121,"id":"0690aa","input":"'''\ndefine a function called \"remove_punctuation\" that removes punctuation from the sentences.\n'''\ndef remove_punctuation(sentences):\n    \n    for i in range(len(sentences)):\n        words = []\n\n        word_list = nltk.word_tokenize(sentences[i])\n\n        for word in word_list:\n            if word not in \",.?!()–``\":\n                words.append(word)\n\n        sentences[i] = ' '.join(words)\n\n    return sentences\nsentences = remove_punctuation(sentences)\nprint(sentences[:10]) #eliminating all punctuation.","kernel":"nlp_env","output":{"0":{"name":"stdout","text":"['portuguese professional footballer eponym film cristiano ronaldo do santos aveiro goih comm portuguese pronunciation : [ kɾiʃˈtjɐnu ʁɔˈnaɫdu ] ; born february portuguese professional footballer play forward premier league club manchester united captain portugal national team', \"often considered best player world widely regarded one greatest player time ronaldo five ballon d'or award [ note ] four european golden shoe european player\", 'trophy career including seven league title five uefa champion league one uefa european championship one uefa nation league', 'ronaldo hold record appearance goal assist champion league goal european championship international goal male player international appearance european male', 'one player made professional career appearance scored official senior career goal club country', 'ronaldo began senior career sporting cp signing manchester united aged winning fa cup first season', \"would also go onto win three consecutive premier league title champion league fifa club world cup ; age first ballon d'or\", \"ronaldo subject then-most expensive association football transfer signed real madrid transfer worth € million £ million trophy including two la liga title two copa del rey four champion league became club 's all-time top goalscorer\", \"back-to-back ballons d'or runner-up three time behind lionel messi perceived career rival\", 'signed juventus transfer worth initial € million £ million expensive transfer italian club expensive player year old']\n"}},"pos":15,"start":1656601309704,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601314307,"exec_count":122,"id":"af90f7","input":"# Install gensim - pip install gensim\nimport nltk\nfrom gensim.models import Word2Vec\nimport matplotlib.pyplot as plt\nnltk.download('punkt')\nfrom wordcloud import WordCloud","kernel":"nlp_env","output":{"0":{"name":"stderr","text":"[nltk_data] Downloading package punkt to /projects/6a848d56-5da1-43fb-\n[nltk_data]     bfc9-9172977ceeb4/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"}},"pos":27,"start":1656601314299,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601314828,"exec_count":123,"id":"730bbd","input":"#Let's go ahead and create a list that's formatted how word2vec needs:\n    # a list of lists where the ith entry in the list is the word tokenizaiton of the ith sentence (after preprocessing)\ntokenized = []\n\nfor sentence in sentences:\n    tokenized.append(nltk.word_tokenize(sentence))","kernel":"nlp_env","pos":28,"start":1656601314763,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601315224,"exec_count":124,"id":"af042b","input":"# print the tokenized list of lists\nprint(tokenized[:10])","kernel":"nlp_env","output":{"0":{"name":"stdout","text":"[['portuguese', 'professional', 'footballer', 'eponym', 'film', 'cristiano', 'ronaldo', 'do', 'santos', 'aveiro', 'goih', 'comm', 'portuguese', 'pronunciation', ':', '[', 'kɾiʃˈtjɐnu', 'ʁɔˈnaɫdu', ']', ';', 'born', 'february', 'portuguese', 'professional', 'footballer', 'play', 'forward', 'premier', 'league', 'club', 'manchester', 'united', 'captain', 'portugal', 'national', 'team'], ['often', 'considered', 'best', 'player', 'world', 'widely', 'regarded', 'one', 'greatest', 'player', 'time', 'ronaldo', 'five', 'ballon', \"d'or\", 'award', '[', 'note', ']', 'four', 'european', 'golden', 'shoe', 'european', 'player'], ['trophy', 'career', 'including', 'seven', 'league', 'title', 'five', 'uefa', 'champion', 'league', 'one', 'uefa', 'european', 'championship', 'one', 'uefa', 'nation', 'league'], ['ronaldo', 'hold', 'record', 'appearance', 'goal', 'assist', 'champion', 'league', 'goal', 'european', 'championship', 'international', 'goal', 'male', 'player', 'international', 'appearance', 'european', 'male'], ['one', 'player', 'made', 'professional', 'career', 'appearance', 'scored', 'official', 'senior', 'career', 'goal', 'club', 'country'], ['ronaldo', 'began', 'senior', 'career', 'sporting', 'cp', 'signing', 'manchester', 'united', 'aged', 'winning', 'fa', 'cup', 'first', 'season'], ['would', 'also', 'go', 'onto', 'win', 'three', 'consecutive', 'premier', 'league', 'title', 'champion', 'league', 'fifa', 'club', 'world', 'cup', ';', 'age', 'first', 'ballon', \"d'or\"], ['ronaldo', 'subject', 'then-most', 'expensive', 'association', 'football', 'transfer', 'signed', 'real', 'madrid', 'transfer', 'worth', '€', 'million', '£', 'million', 'trophy', 'including', 'two', 'la', 'liga', 'title', 'two', 'copa', 'del', 'rey', 'four', 'champion', 'league', 'became', 'club', \"'s\", 'all-time', 'top', 'goalscorer'], ['back-to-back', 'ballons', \"d'or\", 'runner-up', 'three', 'time', 'behind', 'lionel', 'messi', 'perceived', 'career', 'rival'], ['signed', 'juventus', 'transfer', 'worth', 'initial', '€', 'million', '£', 'million', 'expensive', 'transfer', 'italian', 'club', 'expensive', 'player', 'year', 'old']]\n"}},"pos":29,"start":1656601315214,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601322444,"exec_count":127,"id":"04d323","input":"''' Training the Word2Vec model. You should pass:\n1. a list of lists where the ith entry in the list is the word tokenizaiton of the ith sentence\n2. min_count=1 --> Ignores all words with total frequency lower than 1 (i.e., include everything).\n'''\n# create the model\nmodel = Word2Vec(tokenized, min_count=1)\n# get the most common words of the model (it's entire vocabulary)\nmost_common_words = model.wv.index_to_key\n# save the model to use it later\nmodel.save(\"word2vec.model\")\n# model = Word2Vec.load(\"word2vec.model\")","kernel":"nlp_env","pos":31,"start":1656601322282,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601323658,"exec_count":128,"id":"1f7920","input":"#print the first 10 most common words.\nmost_common_words[:10]","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"['ronaldo',\n 'goal',\n \"'s\",\n 'player',\n 'scored',\n 'first',\n 'win',\n 'league',\n 'season',\n 'club']"},"exec_count":128}},"pos":32,"start":1656601323651,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601324785,"exec_count":129,"id":"acefc8","input":"# Look up the most similar words to certain words in your text using the model.wv.most_similar() function","kernel":"nlp_env","pos":33,"start":1656601324776,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601325259,"exec_count":130,"id":"a7aa5f","input":"model.wv.most_similar('ronaldo')","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"[(\"'s\", 0.9231060743331909),\n ('goal', 0.902737021446228),\n ('league', 0.9016129374504089),\n ('united', 0.8803714513778687),\n ('win', 0.8784968256950378),\n ('scored', 0.8763689398765564),\n ('two', 0.8730097413063049),\n ('player', 0.8674589395523071),\n ('first', 0.8636878728866577),\n (';', 0.862720251083374)]"},"exec_count":130}},"pos":34,"start":1656601325246,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601620477,"exec_count":132,"id":"560422","input":"    # Finding Word Vectors - print word vectors for certain words in your text\nvector = model.wv['global']\nprint(vector)","kernel":"nlp_env","output":{"0":{"name":"stdout","text":"[ 0.00762166 -0.00096225  0.00446276  0.00715782 -0.00851666 -0.00965514\n -0.00764323  0.00673699  0.00172892  0.00594591  0.00696188  0.00202102\n  0.0082902   0.00222196  0.00297096  0.00111229  0.00313908  0.00015341\n  0.00345882 -0.0038651  -0.00503764 -0.00356856  0.00206669 -0.00385743\n -0.00404689 -0.00095866 -0.00586797  0.00577915 -0.0034139  -0.00601244\n  0.00677504  0.00672354  0.00170919  0.00144463  0.00689876  0.00913181\n -0.00130134 -0.00672446 -0.00378133 -0.00748031 -0.00122557 -0.00843348\n -0.00038344  0.00469192 -0.00171182  0.00172942  0.00755158  0.00429159\n -0.00438834 -0.00252824 -0.00341358  0.00683122 -0.00844229 -0.00318975\n  0.00426935  0.00251553 -0.00667335 -0.00944583  0.00789154  0.00492486\n -0.00638214 -0.00321562  0.00870726  0.00974391  0.00233326  0.00867034\n -0.00097339 -0.00854438 -0.00991088 -0.0078048  -0.00440884  0.01001767\n -0.00788947 -0.00660684  0.00713036 -0.00738398  0.00414061  0.00640208\n  0.00312708 -0.00543003  0.0084351  -0.00823523 -0.00565162 -0.00492612\n  0.00283207  0.00085666 -0.00569502  0.00685347  0.00121473 -0.00944743\n  0.00069924  0.00140441  0.00609349  0.00990214 -0.00172543 -0.00230958\n  0.00300144  0.00837807 -0.00539613 -0.00155694]\n"}},"pos":36,"start":1656601620466,"state":"done","type":"cell"}
{"cell_type":"code","end":1656601651409,"exec_count":135,"id":"4ef7e1","input":"    ### Finding the most similar words in the model ###\nwordcloud = WordCloud(\n                        background_color='black',\n                        max_words=120,\n                        max_font_size=70, \n                        random_state=20\n                        ).generate(str(sentences))\nfig = plt.figure(1)\nplt.figure(figsize=(10,10))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"<Figure size 432x288 with 0 Axes>"}},"1":{"data":{"image/png":"5a03d348396ab36f9ddf01f7ad22503786757b2d","text/plain":"<Figure size 720x720 with 1 Axes>"},"metadata":{"needs_background":"light"}}},"pos":37,"start":1656601651104,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"01af76","input":"# Redo the word cloud but set stopwords to empty so it looks really bad\nwordcloud = WordCloud(\n                        background_color='white',\n                        max_words=100,\n                        max_font_size=50, \n                        random_state=42, ###SET STOPWORDS = [] and/or include_numbers = True or you will get the same thing!!!\n                        stopwords = [],\n                        include_numbers = True).generate(str(lame_sentences)) \nfig = plt.figure(1)\nplt.figure(figsize=(10,10))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","pos":44,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"1b005f","input":"# Finding a vector of a word, but badly","pos":46,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"250e08","input":"### Finding the most similar words in the model but... you get the idea ###\n\n","pos":47,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"3a8482","input":"","pos":48,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"4b46fc","input":"from nltk.stem import PorterStemmer\n\nstemmer = PorterStemmer()\n# try each of the words below\nstemmer.stem('troubled')\n#stemmer.stem('trouble')\n#stemmer.stem('troubling')\n#stemmer.stem('troubles')","pos":17,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"530fcf","input":"# Training the Word2Vec model (same code as before), but one change: use our lame data that was not preprocessed\n\n# Try printing this after training the model.\nwords = model.wv.index_to_key\nprint(words[:10])","pos":45,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"6f8b2e","input":"'''\nYour code here:\nDefine a function called \"stem_sentences\" that takes in a list of sentences and returns a list of stemmed sentences.\n'''\ndef stem_sentences(sentences):\n    ### Some code goes here. Hint: Try looking up how to stem words in NLTK if you get stuck (or simply use the example above and run stemmer in a loop!). ###\n","pos":18,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"964004","input":"'''\nDoing the same without removing stop words or lemming\n'''\n# tokenize the text using sent_tokenize\n\n# from this list of sentences, create a list of lists where the ith entry in the list is the word tokenizaiton of the ith sentence (after preprocessing)","pos":43,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"c68850","input":"","pos":38,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"d61eae","input":"\nprint(stemmed_sentences[:10])","pos":19,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"e8ec5d","input":"# reFetching the data\nlame_text = \"\"\nfor paragraph in soup.find_all('p'): #The <p> tag defines a paragraph in the webpages\n    lame_text += paragraph.text","pos":42,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"f5faae","input":"similar1, similar2","pos":39,"type":"cell"}
{"cell_type":"markdown","id":"0066ce","input":"","pos":50,"type":"cell"}
{"cell_type":"markdown","id":"41523d","input":"# Natural Language Processing using NLTK","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"5450e0","input":"## NLP Part 3b - Lemmatization\nLemmatization considers the context and converts the word to its meaningful base form. There is a cool tutorial and definition of lemmatization in NLTK [here](https://www.geeksforgeeks.org/python-lemmatization-with-nltk/).","pos":20,"type":"cell"}
{"cell_type":"markdown","id":"5eea24","input":"## NLP Part 2 - Stopwords and Punctuation\nNow we are going to work to remove stopwords and punctuation from our data. Why do you think we are going to do this? Do some research if you don't know yet. ","pos":12,"type":"cell"}
{"cell_type":"markdown","id":"854a06","input":"","pos":1,"type":"cell"}
{"cell_type":"markdown","id":"8810ea","input":"# Word2Vec Model Visualization","pos":26,"type":"cell"}
{"cell_type":"markdown","id":"9df2ba","input":"## Testing our model\n\n","pos":35,"type":"cell"}
{"cell_type":"markdown","id":"c9584a","input":"## Training the Word2Vec model\n\nFor this part you may want to follow a guide [here](https://radimrehurek.com/gensim/models/word2vec.html). \n\n","pos":30,"type":"cell"}
{"cell_type":"markdown","id":"c9f5a2","input":"## NLP Part 1 - Tokenization of paragraphs/sentences\n\nIn this section we are going to tokenize our sentences and words. If you aren't familiar with tokenization, we recommend looking up \"what is tokenization\". \n\nYou should also spend time on the [NLTK documentation](https://www.nltk.org/). If you're not sure how to do something, or get an error, it is best to google it first and ask questions as you go!","pos":7,"type":"cell"}
{"cell_type":"markdown","id":"d2349c","input":"## Reflection\nHow important do you think proper preprocessing in NLP is?","pos":49,"type":"cell"}
{"cell_type":"markdown","id":"d663ca","input":"## NLP Part 0 - Get some Data!\n\nThis section's code is mostly given to you as a review for how you can scrape and manipulate data from the web. ","pos":3,"type":"cell"}
{"cell_type":"markdown","id":"e7a1e9","input":"## NLP Part 4 - POS Tagging\nParts of speech tagging is marking up a word in a text as corresponding to a particular part of speech, based on both its definition and its context.","pos":23,"type":"cell"}
{"cell_type":"markdown","id":"fa40e7","input":"## NLP Part 3a - Stemming the words\nStemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root form. There is an example below!","pos":16,"type":"cell"}
{"cell_type":"markdown","id":"fe7a79","input":"### Why did we do all this work?","pos":41,"type":"cell"}
{"id":0,"time":1656600755153,"type":"user"}
{"last_load":1656599484361,"type":"file"}